{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from drdmannturb.calibration import CalibrationProblem\n",
    "from drdmannturb.data_generator import OnePointSpectraDataGenerator\n",
    "from drdmannturb.shared.parameters import NNParameters, ProblemParameters, LossParameters, PhysicalParameters\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "L = 0.59\n",
    "Gamma = 3.9\n",
    "sigma = 3.4\n",
    "\n",
    "domain = torch.logspace(-1, 2, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewmeeker/miniconda3/envs/KeithProject/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /private/var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_82vavna4yl/croot/pytorch_1686931843901/work/aten/src/ATen/native/TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "pb = CalibrationProblem(\n",
    "    nn_params = NNParameters(\n",
    "        activations = [nn.GELU(), nn.GELU(), nn.GELU()]\n",
    "    ),\n",
    "    prob_params = ProblemParameters(),\n",
    "    loss_params = LossParameters(),\n",
    "    phys_params = PhysicalParameters(\n",
    "        L=0.59,\n",
    "        Gamma=3.9,\n",
    "        sigma=3.4,\n",
    "        domain=domain\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = pb.parameters\n",
    "parameters[:3] = [\n",
    "    np.log(L),\n",
    "    np.log(Gamma),\n",
    "    np.log(sigma)\n",
    "]\n",
    "\n",
    "pb.parameters = parameters[:len(pb.parameters)]\n",
    "\n",
    "k1_data_pts = domain\n",
    "DataPoints = [(k1, 1) for k1 in k1_data_pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = OnePointSpectraDataGenerator(data_points=DataPoints).Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calibrating MannNet...\n",
      "torch.Size([80])\n",
      "Initial loss:  0.11969207666942294\n",
      "\n",
      "=================================\n",
      "[Calibration.py -- calibrate]-> Epoch 0\n",
      "=================================\n",
      "\n",
      "loss  =  0.11969207666942294\n",
      "loss  =  0.07707454992586589\n",
      "loss  =  0.06954747668989249\n",
      "loss  =  0.06345006421463914\n",
      "loss  =  0.0376301352943096\n",
      "loss  =  0.03761761738330146\n",
      "loss  =  0.03756281977546127\n",
      "loss  =  0.03713258733690071\n",
      "loss  =  0.03709939139979264\n",
      "loss  =  0.03690856191355569\n",
      "loss  =  0.036889812814573986\n",
      "loss  =  0.03674205731075728\n",
      "loss  =  0.03664048439654474\n",
      "loss  =  0.03595832491274979\n",
      "loss  =  0.03578934504703538\n",
      "loss  =  0.03478984376145849\n",
      "loss  =  0.034537642006839675\n",
      "loss  =  0.033534414030194554\n",
      "loss  =  0.03279391563851734\n",
      "loss  =  0.02757770828314513\n",
      "loss  =  0.026682759718223266\n",
      "loss  =  0.02544344025772991\n",
      "loss  =  0.024424864322111113\n",
      "loss  =  0.023929963070169667\n",
      "loss  =  0.02367398298914731\n",
      "---------------------------------\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "=================================\n",
      "[Calibration.py -- calibrate]-> Epoch 1\n",
      "=================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewmeeker/miniconda3/envs/KeithProject/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss  =  0.02367398298914731\n",
      "loss  =  0.023469357189433247\n",
      "loss  =  0.023270932756949712\n",
      "loss  =  0.022846781238358045\n",
      "loss  =  0.02274827754511955\n",
      "loss  =  0.02268137434590604\n",
      "loss  =  0.022271721716594785\n",
      "loss  =  0.02222580024745708\n",
      "loss  =  0.021923550869629\n",
      "loss  =  0.021866724761119175\n",
      "loss  =  0.021493339726777864\n",
      "loss  =  0.021420678824496366\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/matthewmeeker/BrownU/Fall23/KeithDeskos/DRDMannTurb/examples/Demo/exp1.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matthewmeeker/BrownU/Fall23/KeithDeskos/DRDMannTurb/examples/Demo/exp1.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pb\u001b[39m.\u001b[39meval(k1_data_pts)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/matthewmeeker/BrownU/Fall23/KeithDeskos/DRDMannTurb/examples/Demo/exp1.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pb\u001b[39m.\u001b[39;49mcalibrate(data\u001b[39m=\u001b[39;49mData)\n",
      "File \u001b[0;32m~/BrownU/Fall23/KeithDeskos/DRDMannTurb/drdmannturb/calibration.py:417\u001b[0m, in \u001b[0;36mCalibrationProblem.calibrate\u001b[0;34m(self, data, model_magnitude_order, optimizer_class)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m=================================\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    414\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch_model_sizes[epoch] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_trainable_magnitude(\n\u001b[1;32m    415\u001b[0m     model_magnitude_order\n\u001b[1;32m    416\u001b[0m )\n\u001b[0;32m--> 417\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep(closure)\n\u001b[1;32m    418\u001b[0m \u001b[39m# TODO: refactor the scheduler things, plateau requires loss\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[39m# scheduler.step(self.loss) #if scheduler\u001b[39;00m\n\u001b[1;32m    420\u001b[0m scheduler\u001b[39m.\u001b[39mstep(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss)\n",
      "File \u001b[0;32m~/miniconda3/envs/KeithProject/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:69\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m instance\u001b[39m.\u001b[39m_step_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     68\u001b[0m wrapped \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance, \u001b[39mcls\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/KeithProject/lib/python3.9/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/KeithProject/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/KeithProject/lib/python3.9/site-packages/torch/optim/lbfgs.py:426\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mobj_func\u001b[39m(x, t, d):\n\u001b[1;32m    424\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_directional_evaluate(closure, x, t, d)\n\u001b[0;32m--> 426\u001b[0m     loss, flat_grad, t, ls_func_evals \u001b[39m=\u001b[39m _strong_wolfe(\n\u001b[1;32m    427\u001b[0m         obj_func, x_init, t, d, loss, flat_grad, gtd)\n\u001b[1;32m    428\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_add_grad(t, d)\n\u001b[1;32m    429\u001b[0m opt_cond \u001b[39m=\u001b[39m flat_grad\u001b[39m.\u001b[39mabs()\u001b[39m.\u001b[39mmax() \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m tolerance_grad\n",
      "File \u001b[0;32m~/miniconda3/envs/KeithProject/lib/python3.9/site-packages/torch/optim/lbfgs.py:99\u001b[0m, in \u001b[0;36m_strong_wolfe\u001b[0;34m(obj_func, x, t, d, f, g, gtd, c1, c2, tolerance_change, max_ls)\u001b[0m\n\u001b[1;32m     97\u001b[0m g_prev \u001b[39m=\u001b[39m g_new\u001b[39m.\u001b[39mclone(memory_format\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mcontiguous_format)\n\u001b[1;32m     98\u001b[0m gtd_prev \u001b[39m=\u001b[39m gtd_new\n\u001b[0;32m---> 99\u001b[0m f_new, g_new \u001b[39m=\u001b[39m obj_func(x, t, d)\n\u001b[1;32m    100\u001b[0m ls_func_evals \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    101\u001b[0m gtd_new \u001b[39m=\u001b[39m g_new\u001b[39m.\u001b[39mdot(d)\n",
      "File \u001b[0;32m~/miniconda3/envs/KeithProject/lib/python3.9/site-packages/torch/optim/lbfgs.py:424\u001b[0m, in \u001b[0;36mLBFGS.step.<locals>.obj_func\u001b[0;34m(x, t, d)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mobj_func\u001b[39m(x, t, d):\n\u001b[0;32m--> 424\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_directional_evaluate(closure, x, t, d)\n",
      "File \u001b[0;32m~/miniconda3/envs/KeithProject/lib/python3.9/site-packages/torch/optim/lbfgs.py:278\u001b[0m, in \u001b[0;36mLBFGS._directional_evaluate\u001b[0;34m(self, closure, x, t, d)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_directional_evaluate\u001b[39m(\u001b[39mself\u001b[39m, closure, x, t, d):\n\u001b[1;32m    277\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_add_grad(t, d)\n\u001b[0;32m--> 278\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(closure())\n\u001b[1;32m    279\u001b[0m     flat_grad \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gather_flat_grad()\n\u001b[1;32m    280\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_param(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/KeithProject/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/BrownU/Fall23/KeithDeskos/DRDMannTurb/drdmannturb/calibration.py:367\u001b[0m, in \u001b[0;36mCalibrationProblem.calibrate.<locals>.closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclosure\u001b[39m():\n\u001b[1;32m    366\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m--> 367\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mOPS(k1_data_pts)\n\u001b[1;32m    368\u001b[0m     w \u001b[39m=\u001b[39m k1_data_pts \u001b[39m*\u001b[39m y_data \u001b[39m/\u001b[39m torch\u001b[39m.\u001b[39msum(k1_data_pts \u001b[39m*\u001b[39m y_data)\n\u001b[1;32m    369\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_fn(\n\u001b[1;32m    370\u001b[0m         y[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurves[i:]], y_data[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurves[i:]], w[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurves[i:]]\n\u001b[1;32m    371\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/KeithProject/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/BrownU/Fall23/KeithDeskos/DRDMannTurb/drdmannturb/one_point_spectra.py:108\u001b[0m, in \u001b[0;36mOnePointSpectra.forward\u001b[0;34m(self, k1_input)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(\n\u001b[1;32m    105\u001b[0m     torch\u001b[39m.\u001b[39mmeshgrid(k1_input, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrid_k2, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrid_k3), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m    106\u001b[0m )\n\u001b[1;32m    107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk123 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m0\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m1\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m2\u001b[39m]\n\u001b[0;32m--> 108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbeta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mEddyLifetime()\n\u001b[1;32m    109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk0 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk\u001b[39m.\u001b[39mclone()\n\u001b[1;32m    110\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk0[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m2\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m2\u001b[39m] \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbeta \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/BrownU/Fall23/KeithDeskos/DRDMannTurb/drdmannturb/one_point_spectra.py:155\u001b[0m, in \u001b[0;36mOnePointSpectra.EddyLifetime\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtype_EddyLifetime \u001b[39min\u001b[39;00m [\n\u001b[1;32m    152\u001b[0m     EddyLifetimeType\u001b[39m.\u001b[39mTAUNET, EddyLifetimeType\u001b[39m.\u001b[39mCUSTOMMLP, EddyLifetimeType\u001b[39m.\u001b[39mTAURESNET\n\u001b[1;32m    153\u001b[0m ]:\n\u001b[1;32m    154\u001b[0m     tau0 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mInitialGuess_EddyLifetime(kL)\n\u001b[0;32m--> 155\u001b[0m     tau \u001b[39m=\u001b[39m tau0 \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtauNet(\n\u001b[1;32m    156\u001b[0m         k \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mLengthScale\n\u001b[1;32m    157\u001b[0m     )  \u001b[39m# This takes a vector as input\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[39m# elif self.type_EddyLifetime == 'customMLP':\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39m#    tau0 = self.InitialGuess_EddyLifetime(kL)\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[39m#    tau = tau0 + self.tauNet(k * self.LengthScale)\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[39m# elif self.type_EddyLifetime == 'tauResNet':\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39m#    tauResNet\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    164\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mWrong EddyLifetime model !\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/KeithProject/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/BrownU/Fall23/KeithDeskos/DRDMannTurb/drdmannturb/nn_modules.py:520\u001b[0m, in \u001b[0;36mCustomNet.forward\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, k: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m    507\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[39m    Forward method implementation\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[39m        _description_\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 520\u001b[0m     k_mod \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mNN(k\u001b[39m.\u001b[39;49mabs())\u001b[39m.\u001b[39mnorm(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    521\u001b[0m     tau \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mRa(k_mod)\n\u001b[1;32m    522\u001b[0m     \u001b[39mreturn\u001b[39;00m tau\n",
      "File \u001b[0;32m~/miniconda3/envs/KeithProject/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/BrownU/Fall23/KeithDeskos/DRDMannTurb/drdmannturb/nn_modules.py:168\u001b[0m, in \u001b[0;36mCustomMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    165\u001b[0m out \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mclone()\n\u001b[1;32m    167\u001b[0m \u001b[39mfor\u001b[39;00m lin, activ \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinears, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivations):\n\u001b[0;32m--> 168\u001b[0m     out \u001b[39m=\u001b[39m activ(lin(out))\n\u001b[1;32m    170\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear_out(out)\n\u001b[1;32m    172\u001b[0m \u001b[39mreturn\u001b[39;00m x \u001b[39m+\u001b[39m out\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pb.eval(k1_data_pts)\n",
    "pb.calibrate(data=Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KeithProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
